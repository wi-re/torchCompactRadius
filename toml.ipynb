{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define countNeighbors_pyArguments_t \\\n",
    "# torch::Tensor queryPositions_, torch::Tensor querySupport_, \\\n",
    "# torch::Tensor sortedPositions_, torch::Tensor sortedSupport_, \\\n",
    "# torch::Tensor domainMin_, torch::Tensor domainMax_, torch::Tensor periodicity_, \\\n",
    "# float_t hCell, torch::Tensor cellBegin_, torch::Tensor cellEnd_, torch::Tensor cellIndices_, torch::Tensor cellLevel_, torch::Tensor cellResolutions_, \\\n",
    "# std::optional<torch::Tensor> hashMapOffset_, std::optional<torch::Tensor> hashMapOccupancy_, std::optional<torch::Tensor> sortedCells_, int32_t hashMapLength, bool verbose\n",
    "\n",
    "# #define countNeighbors_functionArguments_t \\\n",
    "# torch::Tensor queryPositions_, torch::Tensor querySupport_, \\\n",
    "# torch::Tensor sortedPositions_, torch::Tensor sortedSupport_, \\\n",
    "# torch::Tensor domainMin_, torch::Tensor domainMax_, torch::Tensor periodicity_, \\\n",
    "# float_t hCell, torch::Tensor offsets_, \\\n",
    "# torch::Tensor cellBegin_, torch::Tensor cellEnd_, torch::Tensor cellIndices_, torch::Tensor cellLevel_, torch::Tensor cellResolutions_, \\\n",
    "# std::optional<torch::Tensor> hashMapOffset_, std::optional<torch::Tensor> hashMapOccupancy_, std::optional<torch::Tensor> sortedCells_, int32_t hashMapLength, bool verbose, \\\n",
    "# torch::Tensor neighborCounters_, torch::Tensor neighborAccessCounters_, torch::Tensor neighborHashCollisions_, torch::Tensor neighborSynchronousCounters_, torch::Tensor neighborSupports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments_toml = '''\n",
    "\n",
    "queryPositions ={type = \"tensor[scalar_t]\",dim = 2}\n",
    "\n",
    "querySupports.type = \"tensor[scalar_t]\"\n",
    "\n",
    "sortedPositions = {type = \"tensor[scalar_t]\",dim = 2}\n",
    "\n",
    "sortedSupports.type = \"tensor[scalar_t]\"\n",
    "\n",
    "domainMin.type = \"tensor[scalar_t]\"\n",
    "domainMax.type = \"tensor[scalar_t]\"\n",
    "periodicity.type = \"tensor[bool]\"\n",
    "\n",
    "hCell.type = \"scalar_t\"\n",
    "\n",
    "offsets = {type = \"tensor[int32_t]\", dim = 2, pythonArg = false}\n",
    "\n",
    "cellBegin.type = \"tensor[int32_t]\"\n",
    "cellEnd.type = \"tensor[int32_t]\"\n",
    "cellIndices.type = \"tensor[int32_t]\"\n",
    "cellLevel.type = \"tensor[int32_t]\"\n",
    "cellResolutions = {type = \"tensor[int32_t]\", dim = 2}\n",
    "\n",
    "hashMapOffset.type = \"tensor[int32_t]\"\n",
    "hashMapOffset.optional = true\n",
    "hashMapOccupancy.type = \"tensor[int32_t]\"\n",
    "hashMapOccupancy.optional = true\n",
    "sortedCells.type = \"tensor[int32_t]\"\n",
    "sortedCells.optional = true\n",
    "hashMapLength.type = \"int32_t\"\n",
    "hashMapLength.optional = true\n",
    "\n",
    "verbose.type = \"bool\"\n",
    "\n",
    "neighborCounters = {type = \"tensor[int32_t]\", pythonArg = false, const = false}\n",
    "neighborAccessCounters = {type = \"tensor[int32_t]\", pythonArg = false, const = false}\n",
    "neighborHashCollisions = {type = \"tensor[int32_t]\", pythonArg = false, const = false}\n",
    "neighborSynchronousCounters = {type = \"tensor[int32_t]\", pythonArg = false, const = false}\n",
    "neighborSupports = {type = \"tensor[scalar_t]\", pythonArg = false, const = false}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "parsed = toml.loads(arguments_toml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToArgument(key, value, includeType = True, addUnderScore = False, includeOptional = False, functionOnly = False, typeFormat = 'pyBind'):\n",
    "    if not functionOnly and 'pythonArg' in value and value['pythonArg'] == False:\n",
    "        return \"\"\n",
    "    if includeType:\n",
    "        if typeFormat == 'pyBind':\n",
    "            if 'tensor' in value['type']:\n",
    "                type_str = f\"torch::Tensor\"\n",
    "            else:\n",
    "                type_str = f\"{value['type']}\"\n",
    "            if 'optional' in value and value['optional']:\n",
    "                type_str = f\"std::optional<{type_str}>\"\n",
    "        elif typeFormat == 'compute':\n",
    "            if 'tensor' in value['type']:\n",
    "                ty = value['type'].split('[')[1].split(']')[0] if '[' in value['type'] else 'scalar_t'\n",
    "                type_str = f\"{'c' if 'const' not in value or value['const'] else ''}ptr_t<{ty}, {1 if 'dim' not in value else value['dim']}>\"\n",
    "            else:\n",
    "                type_str = f\"{value['type']}\"\n",
    "            \n",
    "    else:\n",
    "        type_str = \"\"\n",
    "\n",
    "    if addUnderScore:\n",
    "        name_str = f\"{key}_\"\n",
    "    else:\n",
    "        name_str = f\"{key}\"\n",
    "\n",
    "    if not includeOptional and 'optional' in value and value['optional']:\n",
    "        return \"\"\n",
    "    return f\"{type_str} {name_str}\"\n",
    "\n",
    "def generateFunctionArguments(parsedToml, **kwargs):\n",
    "    out = []\n",
    "\n",
    "    for key, value in parsedToml.items():\n",
    "        out.append(transformToArgument(key, value, **kwargs))\n",
    "\n",
    "    out = [x for x in out if x != \"\"]\n",
    "\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "generateFunctionArguments(parsed, includeOptional = True, functionOnly = True, typeFormat = 'compute')\n",
    "\n",
    "\n",
    "def generateTensorAccessors(parsedToml, optional = False):\n",
    "    out = []\n",
    "    for key, value in parsedToml.items():\n",
    "        if optional: # only output optional values\n",
    "            if 'optional' in value and value['optional']:\n",
    "                if 'tensor' in value['type']:\n",
    "                    ty = value['type'].split('[')[1].split(']')[0] if '[' in value['type'] else 'scalar_t'\n",
    "                    dim = 1 if 'dim' not in value else value['dim']\n",
    "                    out += [f\"\\tauto {key} = getAccessor<{ty}, {dim}>({key}_.value(), \\\"{key}\\\", useCuda, verbose_);\\n\"]\n",
    "                else:\n",
    "                    out += [f\"\\tauto {key} = {key}_.value();\\n\"]\n",
    "        else:\n",
    "            if 'optional' in value and value['optional']:\n",
    "                continue\n",
    "\n",
    "            if 'tensor' in value['type']:\n",
    "                ty = value['type'].split('[')[1].split(']')[0] if '[' in value['type'] else 'scalar_t'\n",
    "                dim = 1 if 'dim' not in value else value['dim']\n",
    "\n",
    "                out += [f\"\\tauto {key} = getAccessor<{ty}, {dim}>({key}_, \\\"{key}\\\", useCuda, verbose_);\\n\"]\n",
    "            else:\n",
    "                out += [f\"\\tauto {key} = {key}_;\\n\"]\n",
    "    return out\n",
    "\n",
    "# generateTensorAccessors(parsed, optional = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'src/torchCompactRadius/cppSrc/countNeighbors_mlm.h'\n",
    "filePrefix = fileName.split('.')[0].split('/')[-1]\n",
    "with open(fileName, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # print(lines)\n",
    "\n",
    "tomlBegin = lines.index('/** BEGIN TOML\\n')\n",
    "tomlEnd = lines.index('*/ // END TOML\\n')\n",
    "tomlDefinitions = ''.join(lines[tomlBegin + 1: tomlEnd])\n",
    "\n",
    "parsedToml = toml.loads(tomlDefinitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "endOfDefines = lines.index('/// End the definitions for auto generating the function arguments\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixLines = lines[:tomlEnd+1]\n",
    "suffixLines = lines[endOfDefines:]\n",
    "\n",
    "if '// AUTO GENERATE ACCESSORS\\n' in suffixLines:\n",
    "    accessorBegin = suffixLines.index('// AUTO GENERATE ACCESSORS\\n')\n",
    "    accessorEnd = suffixLines.index('// END AUTO GENERATE ACCESSORS\\n')\n",
    "    accessorLines = generateTensorAccessors(parsedToml, optional = False)\n",
    "\n",
    "    suffixLines = suffixLines[:accessorBegin+1] + accessorLines + suffixLines[accessorEnd:]\n",
    "\n",
    "if '// AUTO GENERATE OPTIONAL ACCESSORS\\n' in suffixLines:\n",
    "    accessorBegin = suffixLines.index('// AUTO GENERATE OPTIONAL ACCESSORS\\n')\n",
    "    accessorEnd = suffixLines.index('// END AUTO GENERATE OPTIONAL ACCESSORS\\n')\n",
    "    accessorLines = generateTensorAccessors(parsedToml, optional = True)\n",
    "\n",
    "    suffixLines = suffixLines[:accessorBegin+1] + accessorLines + suffixLines[accessorEnd:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numOptionals = len([x for x in parsedToml.values() if 'optional' in x and x['optional']])\n",
    "\n",
    "pyArguments = ', '.join(generateFunctionArguments(parsedToml, includeOptional = True, functionOnly = False, typeFormat = 'pyBind'))\n",
    "fnArguments = ', '.join(generateFunctionArguments(parsedToml, includeOptional = False, functionOnly = True, typeFormat = 'pyBind', addUnderScore = True))\n",
    "computeArguments = ', '.join(generateFunctionArguments(parsedToml, includeOptional = False, functionOnly = True, typeFormat = 'compute', addUnderScore = False))\n",
    "arguments = ', '.join(generateFunctionArguments(parsedToml, includeType = False, includeOptional = False, functionOnly = True, typeFormat = 'pyBind', addUnderScore = False))\n",
    "arguments_ = ', '.join(generateFunctionArguments(parsedToml, includeType = False, includeOptional = False, functionOnly = True, typeFormat = 'pyBind', addUnderScore = True))\n",
    "\n",
    "if numOptionals > 0:\n",
    "    fnArgumentsOptional = ', '.join(generateFunctionArguments(parsedToml, includeOptional = True, functionOnly = True, typeFormat = 'pyBind', addUnderScore = True))\n",
    "    computeArgumentsOptional = ', '.join(generateFunctionArguments(parsedToml, includeOptional = True, functionOnly = True, typeFormat = 'compute', addUnderScore = False))\n",
    "    argumentsOptional = ', '.join(generateFunctionArguments(parsedToml, includeType = False, includeOptional = True, functionOnly = True, typeFormat = 'pyBind', addUnderScore = False))\n",
    "    argumentsOptional_ = ', '.join(generateFunctionArguments(parsedToml, includeType = False, includeOptional = True, functionOnly = True, typeFormat = 'pyBind', addUnderScore = True))\n",
    "else:\n",
    "    fnArgumentsOptional = fnArguments\n",
    "    computeArgumentsOptional = computeArguments\n",
    "    argumentsOptional = arguments\n",
    "\n",
    "\n",
    "generatedLines = []\n",
    "generatedLines += ['\\n', '// DEF PYTHON BINDINGS\\n']\n",
    "generatedLines += [f'#define {filePrefix}_pyArguments_t {pyArguments}\\n']\n",
    "generatedLines += ['// DEF FUNCTION ARGUMENTS\\n']\n",
    "generatedLines += [f'#define {filePrefix}_functionArguments_t {fnArguments}\\n']\n",
    "generatedLines += [f'#define {filePrefix}_functionArgumentsOptional_t {fnArgumentsOptional}\\n']\n",
    "\n",
    "generatedLines += ['// DEF COMPUTE ARGUMENTS\\n']\n",
    "generatedLines += [f'#define {filePrefix}_computeArguments_t {computeArguments}\\n']\n",
    "generatedLines += [f'#define {filePrefix}_computeArgumentsOptional_t {computeArgumentsOptional}\\n']\n",
    "\n",
    "generatedLines += ['// DEF ARGUMENTS\\n']\n",
    "generatedLines += [f'#define {filePrefix}_arguments_t {arguments}\\n']\n",
    "generatedLines += [f'#define {filePrefix}_argumentsOptional_t {argumentsOptional}\\n']\n",
    "generatedLines += [f'#define {filePrefix}_arguments_t_ {arguments_}\\n']\n",
    "generatedLines += [f'#define {filePrefix}_argumentsOptional_t_ {argumentsOptional_}\\n']\n",
    "\n",
    "generatedLines += ['\\n', '// END PYTHON BINDINGS\\n']\n",
    "\n",
    "with open(fileName, 'w') as f:\n",
    "    f.writelines(prefixLines + generatedLines + suffixLines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Non-optional arguments\n",
      "\tauto input = getAccessor<scalar_t, 2>(input_, \"input\", useCuda);\n",
      "\tauto result = getAccessor<scalar_t, 1>(result_, \"result\", useCuda);\n",
      "# Optional arguments\n",
      "\tauto inputOptional = getAccessor<scalar_t, 2>(inputOptional_.value(), \"inputOptional\", useCuda);\n",
      " input,  dim,  index\n"
     ]
    }
   ],
   "source": [
    "def transformToArgument(argument, includeType = True, addUnderScore = False, includeOptional = False, functionOnly = False):\n",
    "    if not functionOnly and argument['functionOnly']:\n",
    "        return \"\"\n",
    "    if includeType:\n",
    "        if argument['type'] == 'tensor':\n",
    "            type_str = f\"torch::Tensor\"\n",
    "        else:\n",
    "            type_str = f\"{argument['type']}\"\n",
    "    else:\n",
    "        type_str = \"\"\n",
    "    if addUnderScore and argument['type'] == 'tensor':\n",
    "        name_str = f\"{argument['name']}_\"\n",
    "    else:\n",
    "        name_str = f\"{argument['name']}\"\n",
    "    if not includeOptional and 'optional' in argument and argument['optional']:\n",
    "        return \"\"\n",
    "    return f\"{type_str} {name_str}\"\n",
    "\n",
    "def print_arguments(arguments, functionOnly=False, addUnderScore=True, includeType=True, includeOptional=False):\n",
    "    processed = [transformToArgument(arg, functionOnly=functionOnly, addUnderScore=addUnderScore, includeType=includeType, includeOptional=includeOptional) for arg in arguments]\n",
    "    processed_non_empty = [arg for arg in processed if arg]\n",
    "    # print(\", \".join(processed_non_empty))\n",
    "    return \", \".join(processed_non_empty)\n",
    "\n",
    "\n",
    "def generateProcessArgumentsNonOptional(arguments):\n",
    "    # print(f\"auto getFunctionArguments({print_arguments(arguments, functionOnly=True)}, bool useCuda){{\")\n",
    "    for argument in arguments:\n",
    "        if 'optional' in argument and argument['optional']: \n",
    "            continue\n",
    "        if argument['type'] == 'tensor':\n",
    "            print(f\"\\tauto {argument['name']} = getAccessor<{argument['tensor_type']}, {argument['dim']}>({argument['name']}_, \\\"{argument['name']}\\\", useCuda);\")\n",
    "    # print(\"}\")\n",
    "\n",
    "def generateProcessArgumentsOptional(arguments):\n",
    "    for argument in arguments:\n",
    "        if not 'optional' in argument or not argument['optional']:\n",
    "            continue\n",
    "        if argument['type'] == 'tensor':\n",
    "            print(f\"\\tauto {argument['name']} = getAccessor<{argument['tensor_type']}, {argument['dim']}>({argument['name']}_.value(), \\\"{argument['name']}\\\", useCuda);\")\n",
    "\n",
    "# print_arguments(arguments)\n",
    "\n",
    "print('# Non-optional arguments')\n",
    "generateProcessArgumentsNonOptional(arguments)\n",
    "\n",
    "print('# Optional arguments')\n",
    "generateProcessArgumentsOptional(arguments)\n",
    "\n",
    "\n",
    "print(print_arguments(arguments, addUnderScore=False, includeOptional=False, includeType=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchSPH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
